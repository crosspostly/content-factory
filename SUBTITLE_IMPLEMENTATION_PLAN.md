# Subtitle Implementation Plan (MVP, основано на текущем коде)

**Дата обновления:** 2025-12-16  
**Статус:** PLANNING  
**Источник правды:** текущий репозиторий (см. `docs/ACTUAL_STATUS.md`).

> Этот документ обновлён в рамках rebase документации: устаревшие разделы и ссылки на отсутствующие компоненты удалены/сокращены (>50%), а оставшееся — уточнено по коду (~40%).

## 0) Текущее состояние

- В `core/generators/video_renderer.py` нет шагов субтитров.
- В `core/orchestrators/pipeline_orchestrator.py` нет шага субтитров.
- В `config/shared.yaml` есть блок `subtitles`, но он не используется.

## 1) Цель MVP

Добавить **burn-in subtitles** (встроенные субтитры) для видео, генерируемых classic pipeline:
- `shorts`
- `ad`
- (опционально) `long_form`

MVP не требует распознавания речи: субтитры строятся **из текста сценария**, который уже есть.

## 2) Почему субтитры из текста, а не из аудио

В текущей архитектуре pipeline уже имеет:
- исходный текст сценария (`script` dict),
- оценку длительности (`audio_map["total_duration_sec"]`),
- структуру long_form (`script["blocks"]`).

Это позволяет сделать рабочие субтитры без тяжелых зависимостей и без GPU.

## 3) Предлагаемый алгоритм тайминга

### 3.1 Shorts / Ad

1) Берём полный текст озвучки:
- shorts: `script["script"]`
- ad: `script["narration_text"]`

2) Разбиваем на строки по правилам:
- предложения (по `.`, `!`, `?`) и/или
- ограничение длины строки (например 40–60 символов).

3) Распределяем время:
- общий диапазон: `0 → audio_map["total_duration_sec"]`
- доля строки = `len(line) / sum(len(all_lines))`

4) Генерируем SRT как текст (в памяти).

### 3.2 Long form

Учитываем структуру:
- intro/outro (если нужно)
- blocks: love/money/health

Для каждого блока:
- берём длительность WAV из `audio_map["blocks"][block]` (MoviePy уже умеет измерить duration через `AudioFileClip`).
- строим SRT сегменты в пределах тайм-окна блока и сдвигаем глобальный timestamp.

## 4) Встраивание в видео

### Вариант A (MVP): burn-in в `video_renderer.py`

- После построения финального клипа добавлять слой субтитров как набор `TextClip`/PIL-оверлеев с таймингом.
- Плюс: без внешних subprocess.
- Минус: `TextClip` может зависеть от окружения; возможно понадобится PIL-first реализация.

### Вариант B: burn-in через ffmpeg

- Экспортировать SRT во временный файл.
- Запустить ffmpeg с фильтром `subtitles=...` и получить новый mp4.
- Плюс: стабильнее для субтитров.
- Минус: дополнительный системный бинарь/вызов.

## 5) Точки интеграции (существующие файлы)

- `core/generators/video_renderer.py` — добавить опциональный шаг.
- `core/orchestrators/pipeline_orchestrator.py` — включение через config/CLI, логирование артефактов.
- `config/shared.yaml` — использовать существующий блок `subtitles` (например `enabled`, `font`, `font_size`, `color`, `position`).

## 6) Definition of Done

- При включённом `subtitles.enabled` видео содержит читаемые субтитры.
- В `/docs` нет ссылок на отсутствующие subtitle-модули: документация отражает реальную имплементацию.
- Добавлен минимальный тест/смоук сценарий (хотя бы для генерации SRT из текста и таймингов).

## 7) Ограничения MVP

- Тайминги будут приблизительными (особенно до фикса TTS).
- Для long_form сначала лучше внедрить короткий формат (shorts/ad), затем расширять.
