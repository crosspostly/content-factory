name: Auto-Fix Agent

on:
  workflow_run:
    workflows: ["tests.yml", "part1-test.yml"]
    types: [completed]

jobs:
  analyze-failure:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'failure' }}
    permissions:
      contents: write
      actions: read
      issues: write
      pull-requests: write
    
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Get workflow run details
        id: workflow
        run: |
          echo "workflow_name=${{ github.event.workflow_run.name }}" >> $GITHUB_OUTPUT
          echo "workflow_id=${{ github.event.workflow_run.id }}" >> $GITHUB_OUTPUT
          echo "run_number=${{ github.event.workflow_run.run_number }}" >> $GITHUB_OUTPUT
          echo "head_branch=${{ github.event.workflow_run.head_branch }}" >> $GITHUB_OUTPUT
          echo "head_sha=${{ github.event.workflow_run.head_sha }}" >> $GITHUB_OUTPUT
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Setup Ollama for Qwen (cached)
        uses: actions/cache@v4
        with:
          path: ~/.ollama
          key: ollama-qwen-Linux
          restore-keys: ollama-qwen-
      
      - name: Install Ollama & pull Qwen model
        run: |
          curl -fsSL https://ollama.ai/install.sh | sh
          # Start Ollama in background
          ollama serve &
          sleep 3
          # Pull smaller model for GitHub Actions (1.5B fits in 7GB limit)
          ollama pull qwen2.5-coder:1.5b
          echo "âœ… Qwen model ready"
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install google-generativeai openai requests pyyaml pandas ollama
      
      - name: Fetch GitHub Actions logs
        id: logs
        run: |
          python3 << 'PYTHON_SCRIPT'
          import subprocess
          import os
          
          workflow_id = "${{ steps.workflow.outputs.workflow_id }}"
          
          result = subprocess.run(
              ["gh", "run", "view", workflow_id, "--log"],
              capture_output=True,
              text=True,
              env={**os.environ, "GH_TOKEN": "${{ github.token }}"}
          )
          
          logs = result.stdout + result.stderr
          
          with open("/tmp/workflow_logs.txt", "w") as f:
              f.write(logs)
          
          # Extract error section
          lines = logs.split("\n")
          error_lines = []
          capture = False
          for line in lines:
              if "error" in line.lower() or "failed" in line.lower() or capture:
                  error_lines.append(line)
                  capture = True
              if capture and len(error_lines) > 100:
                  break
          
          error_summary = "\n".join(error_lines[-50:])
          
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"error_summary<<EOF\n{error_summary}\nEOF\n")
          
          PYTHON_SCRIPT
      
      - name: Analyze with Qwen
        id: analysis
        env:
          GOOGLE_AI_API_KEY: ${{ secrets.GOOGLE_AI_API_KEY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import os
          import sys
          sys.path.insert(0, os.getcwd())
          
          from core.utils.model_router import generate_text
          from core.utils.config_loader import ProjectConfig
          
          # Determine which model to use
          use_qwen = True  # Try Qwen first (local, free)
          model = "qwen2.5-coder:1.5b"
          
          if not use_qwen or not os.getenv("OLLAMA_HOST"):
              # Fallback to Gemini
              model = "gemini-2.0-flash"
              use_qwen = False
          
          print(f"ðŸ¤– Using model: {model}")
          
          # Read logs
          with open("/tmp/workflow_logs.txt", "r") as f:
              logs = f.read()[-3000:]  # Last 3000 chars
          
          prompt = f"""You are an expert DevOps engineer and software developer.
          
          A GitHub Actions workflow failed. Analyze the error and provide a detailed technical task.
          
          Workflow Name: ${{ steps.workflow.outputs.workflow_name }}
          Branch: ${{ steps.workflow.outputs.head_branch }}
          Run #${{ steps.workflow.outputs.run_number }}
          
          Error Logs:
          ```
          {logs}
          ```
          
          Provide analysis in this JSON format:
          {{
            "problem": "Brief description of what failed",
            "root_cause": "Why it happened",
            "severity": "critical|high|medium|low",
            "solution_steps": ["step 1", "step 2", ...],
            "code_fix": "Python/YAML code to fix (if applicable) or empty string",
            "file_to_modify": "path/to/file or null",
            "suggested_commit_message": "git commit message",
            "technical_task": "Detailed technical task for fixing",
            "auto_fix_possible": true/false
          }}
          
          Be precise and actionable."""
          
          try:
              # Create minimal config for model_router
              class GenConfig:
                  primary_model = model
                  fallback_models = ["gemini-2.0-flash"] if use_qwen else []
                  temperature = 0.7
                  max_retries = 1
              
              class Config:
                  generation = GenConfig()
              
              response = generate_text(Config(), prompt)
              
              # Parse JSON from response
              import re
              match = re.search(r'\{[\s\S]*\}', response)
              if match:
                  analysis = json.loads(match.group())
              else:
                  raise ValueError("No JSON found in response")
          
          except Exception as e:
              print(f"Error calling LLM: {e}")
              analysis = {
                  "problem": f"LLM analysis failed: {str(e)}",
                  "root_cause": "Could not analyze logs",
                  "severity": "high",
                  "solution_steps": [],
                  "auto_fix_possible": False,
                  "code_fix": ""
              }
          
          # Save analysis
          with open("/tmp/analysis.json", "w") as f:
              json.dump(analysis, f, indent=2)
          
          # Output for next steps
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"problem={analysis.get('problem', 'Unknown')[:100]}\n")
              f.write(f"severity={analysis.get('severity', 'medium')}\n")
              f.write(f"auto_fix_possible={str(analysis.get('auto_fix_possible', False)).lower()}\n")
              f.write(f"model_used={'qwen' if use_qwen else 'gemini'}\n")
          
          print(json.dumps(analysis, indent=2))
          
          PYTHON_SCRIPT
      
      - name: Create GitHub Issue
        if: always()
        id: issue
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import subprocess
          import os
          from datetime import datetime
          
          with open("/tmp/analysis.json", "r") as f:
              analysis = json.load(f)
          
          issue_title = f"ðŸ”´ [{analysis.get('severity', 'medium').upper()}] {analysis.get('problem', 'Unknown')[:80]}"
          
          issue_body = f"""## ðŸš¨ Failure Analysis
          
          **Workflow:** ${{ steps.workflow.outputs.workflow_name }}
          **Run:** [${{ steps.workflow.outputs.run_number }}](https://github.com/${{ github.repository }}/actions/runs/${{ steps.workflow.outputs.workflow_id }})
          **Branch:** `${{ steps.workflow.outputs.head_branch }}`
          **Commit:** `${{ steps.workflow.outputs.head_sha }}`
          **AI Model Used:** `${{ steps.analysis.outputs.model_used }}`
          
          ### Problem
          {analysis.get('problem', 'N/A')}
          
          ### Root Cause
          {analysis.get('root_cause', 'N/A')}
          
          ### Severity
          **{analysis.get('severity', 'medium').upper()}**
          
          ### Solution Steps
          {chr(10).join(f'- {step}' for step in analysis.get('solution_steps', []))}
          
          ### Technical Task
          {analysis.get('technical_task', 'N/A')}
          
          ### Suggested Code Fix
          ```python
          {analysis.get('code_fix', 'N/A')}
          ```
          
          ### Auto-Fix Status
          - Auto-fix possible: `{analysis.get('auto_fix_possible', False)}`
          - Analyzed with: `{os.getenv("MODEL_USED", "unknown")}`
          
          ---
          *Generated by Auto-Fix Agent ðŸ¤– at {datetime.now().isoformat()}*
          """
          
          result = subprocess.run(
              [
                  "gh", "issue", "create",
                  "--title", issue_title,
                  "--body", issue_body,
                  "--label", "bug,auto-generated,ai-analyzed"
              ],
              capture_output=True,
              text=True,
              env={**os.environ, "GH_TOKEN": "${{ github.token }}"}
          )
          
          if result.returncode == 0:
              issue_url = result.stdout.strip()
              print(f"âœ… Created issue: {issue_url}")
              with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                  f.write(f"issue_url={issue_url}\n")
          else:
              print(f"âš ï¸ Failed to create issue: {result.stderr}")
          
          PYTHON_SCRIPT
      
      - name: Create PR with Auto-Fix
        if: ${{ steps.analysis.outputs.auto_fix_possible == 'true' }}
        id: pr
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import os
          import subprocess
          import datetime
          
          with open("/tmp/analysis.json", "r") as f:
              analysis = json.load(f)
          
          file_to_modify = analysis.get('file_to_modify')
          code_fix = analysis.get('code_fix', '').strip()
          commit_msg = analysis.get('suggested_commit_message')
          
          if not file_to_modify or not code_fix:
              print("âš ï¸ No code fix to apply")
              exit(0)
          
          print(f"ðŸ”§ Creating PR with auto-fix...")
          print(f"ðŸ“„ File: {file_to_modify}")
          
          timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
          branch_name = f"auto-fix/run-${{ steps.workflow.outputs.run_number }}-{timestamp}"
          
          subprocess.run(["git", "config", "user.email", "auto-fix-agent@github.com"])
          subprocess.run(["git", "config", "user.name", "Auto-Fix Agent"])
          subprocess.run(["git", "checkout", "-b", branch_name, "origin/main"])
          
          if os.path.exists(file_to_modify):
              with open(file_to_modify, "w") as f:
                  f.write(code_fix)
              
              subprocess.run(["git", "add", file_to_modify])
              result = subprocess.run(
                  ["git", "commit", "-m", f"{commit_msg}\n\n[auto-fix-agent run #${{ steps.workflow.outputs.run_number }}]\nWorkflow: ${{ steps.workflow.outputs.workflow_name }}"],
                  capture_output=True,
                  text=True
              )
              
              if result.returncode == 0:
                  result = subprocess.run(["git", "push", "-u", "origin", branch_name], capture_output=True, text=True)
                  
                  if result.returncode == 0:
                      print(f"âœ… Pushed branch: {branch_name}")
                      
                      pr_title = f"ðŸ”§ Auto-Fix: {analysis.get('problem', 'Unknown')[:60]}"
                      pr_body = f"""## Auto-Fix PR
                      
                      **Issue:** {analysis.get('problem', 'N/A')}
                      **Root Cause:** {analysis.get('root_cause', 'N/A')}
                      **Severity:** {analysis.get('severity', 'medium')}
                      **AI Model:** `${{ steps.analysis.outputs.model_used }}`
                      
                      ### Solution
                      {chr(10).join(f'- {step}' for step in analysis.get('solution_steps', []))}
                      
                      ### Changed Files
                      - `{file_to_modify}`
                      
                      ### Workflow Run
                      [${{ steps.workflow.outputs.workflow_name }} #${{ steps.workflow.outputs.run_number }}](https://github.com/${{ github.repository }}/actions/runs/${{ steps.workflow.outputs.workflow_id }})
                      
                      ---
                      *Created by Auto-Fix Agent ðŸ¤– with ${{ steps.analysis.outputs.model_used }} AI*
                      *Please review and merge manually*
                      """
                      
                      result = subprocess.run(
                          [
                              "gh", "pr", "create",
                              "--base", "main",
                              "--head", branch_name,
                              "--title", pr_title,
                              "--body", pr_body,
                              "--label", "auto-generated,auto-fix,ai-generated"
                          ],
                          capture_output=True,
                          text=True,
                          env={**os.environ, "GH_TOKEN": "${{ github.token }}"}
                      )
                      
                      if result.returncode == 0:
                          pr_url = result.stdout.strip()
                          print(f"âœ… Created PR: {pr_url}")
                          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                              f.write(f"pr_url={pr_url}\n")
          
          PYTHON_SCRIPT
      
      - name: Summary
        if: always()
        run: |
          echo "## ðŸ¤– Auto-Fix Agent Summary"
          echo ""
          echo "**Status:** ${{ job.status }}"
          echo "**Workflow:** ${{ steps.workflow.outputs.workflow_name }}"
          echo "**AI Model:** ${{ steps.analysis.outputs.model_used }}"
          echo "**Severity:** ${{ steps.analysis.outputs.severity }}"
          echo "**Auto-fix possible:** ${{ steps.analysis.outputs.auto_fix_possible }}"
          echo ""
          if [ "${{ steps.issue.outputs.issue_url }}" != "" ]; then
            echo "**Issue:** ${{ steps.issue.outputs.issue_url }}"
          fi
          if [ "${{ steps.pr.outputs.pr_url }}" != "" ]; then
            echo "**PR:** ${{ steps.pr.outputs.pr_url }}"
          fi
          echo ""
          echo "âœ… Qwen Ð½Ð° Ollama - Ð´ÐµÐ±Ð°Ð³Ð³Ð¸Ð½Ð³ Ð¸ Ñ„Ð¸ÐºÑÐ¸Ð½Ð³ Ð¾ÑˆÐ¸Ð±Ð¾Ðº!"
