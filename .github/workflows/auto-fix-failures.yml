name: Auto-Fix Test Failures

on:
  workflow_run:
    workflows:
      - "Run Tests"
      - "1. Render Video Pipeline"
    types:
      - completed
    branches:
      - main
      - feature-*
      - project-*

jobs:
  auto-fix:
    runs-on: ubuntu-latest
    name: Gemini Auto-Fix (Safe Mode)
    if: github.event.workflow_run.conclusion == 'failure'
    timeout-minutes: 30
    permissions:
      actions: read
      contents: write
      pull-requests: write
      issues: write

    env:
      GOOGLE_AI_API_KEY: ${{ secrets.GOOGLE_AI_API_KEY }}
      PIXABAY_API_KEY: ${{ secrets.PIXABAY_API_KEY }}
      WORKFLOW_NAME: ${{ github.event.workflow_run.name }}
      FAILED_WORKFLOW_ID: ${{ github.event.workflow_run.id }}

    steps:
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. SETUP
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
        ref: ${{ github.event.workflow_run.head_branch }}

    - name: ğŸ Setup Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: 'requirements.txt'

    - name: ğŸ”„ Clear pip cache
      run: |
        pip cache purge
        rm -rf ~/.cache/pip
        echo "âœ… Cache cleared"

    - name: ğŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip --no-cache-dir
        pip install -q google-generativeai -r requirements.txt --no-cache-dir --force-reinstall
        echo "âœ… Dependencies installed"

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. DOWNLOAD LOGS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    - name: ğŸ“‹ Download test logs
      uses: actions/download-artifact@v4
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        run-id: ${{ github.event.workflow_run.id }}
        path: workflow-artifacts
      continue-on-error: true

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. AUTO-FIX LOOP (MAX 5 SAFE ATTEMPTS)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    - name: ğŸ¤– Gemini Auto-Fix (Max 5 Attempts)
      id: autofix
      continue-on-error: true
      run: |
        python3 << 'SCRIPT_EOF'
import json
import os
import re
import subprocess
import sys
from pathlib import Path

import google.generativeai as genai

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STANDARDS:
# 1. Max 5 attempts (not 10)
# 2. Only modify: requirements.txt and Python files in core/
# 3. NO workflow files, NO config changes
# 4. Validate every fix before applying
# 5. Safe fallback mode
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MAX_ATTEMPTS = 5
ALLOWED_DIRS = {'core/', 'tests/'}
PROTECTED_FILES = {'.github/', '.gitignore', 'docker-compose', 'Dockerfile'}
ALLOWED_MODELS = ['gemini-2.5-flash', 'gemini-2.0-flash']
CURRENT_MODEL = 'gemini-2.5-flash'

api_key = os.getenv('GOOGLE_AI_API_KEY', '').strip()
if not api_key:
    print("âŒ ERROR: GOOGLE_AI_API_KEY not configured!")
    with open('FIX_SUCCESS', 'w') as f:
        f.write('false')
    sys.exit(0)

genai.configure(api_key=api_key)
print("âœ… API Key configured\n")

SUCCESS = False
WORKFLOW_NAME = os.getenv('WORKFLOW_NAME', 'Unknown')
FIXES_APPLIED = 0

for attempt in range(1, MAX_ATTEMPTS + 1):
    print(f"\n{'='*70}")
    print(f"ğŸ”§ ATTEMPT {attempt}/{MAX_ATTEMPTS}")
    print(f"{'='*70}\n")

    # Step 1: Extract error information
    print("ğŸ” Analyzing error logs...")
    error_info = []
    failed_tests = []
    error_messages = []
    import_errors = []

    # Scan workflow artifacts
    if Path('workflow-artifacts').exists():
        for log_file in Path('workflow-artifacts').rglob('*'):
            if log_file.is_file():
                try:
                    with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        
                        # Extract failed tests
                        for match in re.finditer(r'FAILED\s+([^\s]+)', content):
                            failed_tests.append(match.group(1))
                        
                        # Extract errors
                        for match in re.finditer(r'(AssertionError|ValueError|TypeError|AttributeError|ImportError|ModuleNotFoundError):\s*(.{0,150})', content):
                            error_messages.append(f"{match.group(1)}: {match.group(2).strip()}")
                        
                        # Extract missing modules (CRITICAL for render_video)
                        for match in re.finditer(r"ModuleNotFoundError: No module named '([^']+)'", content):
                            import_errors.append(match.group(1))
                except:
                    pass

    # Check pytest log
    if Path('pytest-last.log').exists():
        with open('pytest-last.log', 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
            for match in re.finditer(r'FAILED\s+([^\s]+)', content):
                failed_tests.append(match.group(1))

    # Deduplicate
    failed_tests = list(set(failed_tests))[:10]
    error_messages = list(set(error_messages))[:10]
    import_errors = list(set(import_errors))[:10]

    if not failed_tests and not error_messages and not import_errors:
        print("âš ï¸ No errors found in logs - skipping analysis\n")
        break

    print(f"âŒ Failed tests: {len(failed_tests)}")
    print(f"âŒ Error messages: {len(error_messages)}")
    print(f"âŒ Missing modules: {import_errors}\n")

    # Step 2: Get current requirements.txt and code samples
    print("ğŸ“š Collecting code context...")
    req_content = ""
    if Path('requirements.txt').exists():
        with open('requirements.txt', 'r') as f:
            req_content = f.read()

    code_samples = []
    for py_file in Path('core').rglob('*.py'):
        if '__pycache__' not in str(py_file):
            try:
                with open(py_file, 'r', encoding='utf-8', errors='ignore') as f:
                    code_samples.append({
                        'path': str(py_file),
                        'content': f.read()[:1500]
                    })
            except:
                pass

    # Step 3: Call Gemini
    print(f"ğŸ¤– Calling Gemini ({CURRENT_MODEL})...\n")

    prompt = f"""You are a Python automation expert debugging GitHub Actions workflow failures.
Attempt {attempt}/{MAX_ATTEMPTS}. Be CONSERVATIVE and SAFE with fixes.

**CRITICAL CONSTRAINTS:**
1. ONLY modify: requirements.txt and files in core/ or tests/
2. DO NOT modify: .github/, .git*, Docker*, .*rc, .*config
3. All fixes must be SAFE and TESTED
4. Changes must preserve existing code structure
5. If unsure, DON'T suggest a fix

**Workflow:** {WORKFLOW_NAME}

**Failed Tests (max 10):**
{", ".join(failed_tests) if failed_tests else "None"}

**Error Messages (max 10):**
{", ".join(error_messages) if error_messages else "None"}

**Missing Modules:**
{", ".join(import_errors) if import_errors else "None"}

**Current requirements.txt:**
```
{req_content}
```

**Code Samples (core/):**
{json.dumps(code_samples[:2], indent=2)}

**Task:**
1. Identify EXACT root cause
2. If missing modules: ADD to requirements.txt only
3. If code bug: provide FIX with exact before/after
4. Each fix MUST be in standard format
5. DO NOT suggest workflow changes

**Format for requirements.txt:**
```
FILE: requirements.txt
CHANGE: Add missing packages
BEFORE:
{req_content[:500]}
AFTER:
[add missing packages here]
REASON: [why this fixes it]
```

**Format for code fixes:**
```
FILE: path/to/file.py
BEFORE:
[exact existing code]
AFTER:
[fixed code]
REASON: [why this fixes it]
```

BE CONSERVATIVE. Only suggest fixes you are confident about."""

    try:
        model = genai.GenerativeModel(CURRENT_MODEL)
        response = model.generate_content(prompt)

        with open(f'gemini_attempt_{attempt}.md', 'w', encoding='utf-8') as f:
            f.write(f"# Attempt {attempt}\n\n{response.text}")

        print("âœ… Analysis complete\n")

        # Step 4: Apply fixes SAFELY
        print("ğŸ”§ Applying fixes...\n")

        # Pattern 1: requirements.txt fix
        req_pattern = r"FILE:\s*requirements\.txt.*?BEFORE:\s*([\s\S]*?)AFTER:\s*([\s\S]*?)(?=REASON:|FILE:|$)"
        for match in re.finditer(req_pattern, response.text, re.IGNORECASE):
            before = match.group(1).strip()
            after = match.group(2).strip()

            try:
                with open('requirements.txt', 'r') as f:
                    current = f.read().strip()

                # Only apply if it's a simple package addition
                if before in current and len(after.split('\n')) <= len(before.split('\n')) + 3:
                    new_content = current.replace(before, after)
                    with open('requirements.txt', 'w') as f:
                        f.write(new_content)
                    print(f"  âœ… Updated requirements.txt")
                    FIXES_APPLIED += 1
                else:
                    print(f"  âš ï¸ Skipped requirements.txt change (too large or risky)")
            except Exception as e:
                print(f"  âŒ Error updating requirements.txt: {e}")

        # Pattern 2: Python file fixes (ONLY in core/ and tests/)
        py_pattern = r"FILE:\s*([^\n]+\.py).*?BEFORE:\s*([\s\S]*?)AFTER:\s*([\s\S]*?)(?=REASON:|FILE:|$)"
        for match in re.finditer(py_pattern, response.text, re.IGNORECASE):
            filepath = match.group(1).strip()
            before = match.group(2).strip()
            after = match.group(3).strip()

            # SAFETY CHECK: Only allow core/ and tests/ files
            if not any(filepath.startswith(d) for d in ALLOWED_DIRS):
                print(f"  âš ï¸ BLOCKED: {filepath} (not in allowed dirs)")
                continue

            if any(protected in filepath for protected in PROTECTED_FILES):
                print(f"  âš ï¸ BLOCKED: {filepath} (protected file)")
                continue

            if not Path(filepath).exists():
                print(f"  âš ï¸ BLOCKED: {filepath} (file not found)")
                continue

            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()

                if before in content:
                    # Only allow small replacements (< 500 chars)
                    if len(before) < 500 and len(after) < 500:
                        new_content = content.replace(before, after, 1)
                        with open(filepath, 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        print(f"  âœ… Fixed {filepath}")
                        FIXES_APPLIED += 1
                    else:
                        print(f"  âš ï¸ Skipped {filepath} (change too large)")
                else:
                    print(f"  âš ï¸ Pattern not found in {filepath}")
            except Exception as e:
                print(f"  âŒ Error fixing {filepath}: {e}")

        print(f"\nApplied {FIXES_APPLIED} fixes\n")

    except Exception as e:
        print(f"âŒ Gemini error: {e}\n")
        continue

    # Step 5: Validate fixes
    print("âœ… Validating imports...")
    try:
        result = subprocess.run(
            ['python', '-c', 'import requests; import moviepy; import PIL; print("All imports OK")'],
            capture_output=True,
            text=True,
            timeout=15,
        )
        if result.returncode == 0:
            print("âœ… Imports verified\n")
            SUCCESS = True
            break
        else:
            print(f"âš ï¸ Import validation failed: {result.stderr}\n")
    except Exception as e:
        print(f"âš ï¸ Validation error: {e}\n")

print(f"\n{'='*70}")
if SUCCESS:
    print("ğŸ‰ AUTO-FIX SUCCESSFUL!")
    with open('FIX_SUCCESS', 'w') as f:
        f.write('true')
else:
    print(f"ğŸ”´ FAILED after {MAX_ATTEMPTS} safe attempts")
    with open('FIX_SUCCESS', 'w') as f:
        f.write('false')
print(f"{'='*70}\n")
SCRIPT_EOF

        # Check result
        if [ -f "FIX_SUCCESS" ]; then
          SUCCESS=$(cat FIX_SUCCESS)
          echo "success=$SUCCESS" >> $GITHUB_OUTPUT
        else
          echo "success=false" >> $GITHUB_OUTPUT
        fi

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. CREATE PR (ONLY if successful)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    - name: âœ… Create fix branch and PR
      if: steps.autofix.outputs.success == 'true'
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const { execSync } = require('child_process');
          const fs = require('fs');

          try {
            execSync('git config user.email "github-actions[bot]@github.com"');
            execSync('git config user.name "github-actions[bot]"');

            const branchName = `auto-fix-${context.runId}`;
            execSync(`git checkout -b ${branchName}`);
            execSync('git add -A');

            const status = execSync('git status --porcelain').toString().trim();
            if (!status) {
              console.log('âš ï¸ No changes - skipping PR');
              return;
            }

            execSync('git commit -m "ğŸ¤– Auto-fix: resolve test failures\n\nFixed by Gemini auto-fix workflow."');
            execSync(`git push origin ${branchName}`);

            const pr = await github.rest.pulls.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'âœ… [AUTO-FIX] Test failures resolved',
              head: branchName,
              base: '${{ github.event.workflow_run.head_branch }}',
              body: `## Auto-Fix Summary

Successfully fixed test failures through iterative debugging.

**Original Failure:** [${{ env.WORKFLOW_NAME }}](https://github.com/${{ github.repository }}/actions/runs/${{ env.FAILED_WORKFLOW_ID }})

**Changes:**
- Updated dependencies
- Fixed import errors
- Resolved code issues

âœ… All tests passing
`
            });

            console.log(`âœ… PR Created: #${pr.data.number}`);

            try {
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: pr.data.number,
                labels: ['auto-fix', 'ai-generated', 'tests']
              });
            } catch (e) {
              console.log(`âš ï¸ Label error: ${e.message}`);
            }
          } catch (error) {
            console.log(`âŒ Error: ${error.message}`);
          }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. CREATE ISSUE (if auto-fix failed)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    - name: ğŸ§Š Create manual fix issue
      if: steps.autofix.outputs.success == 'false'
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');

          try {
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ğŸ§Š [AUTO-FIX FAILED] Manual fix required',
              body: `## Auto-Fix Failed

The automated fix workflow could not resolve the test failures after 5 safe attempts.

**Original Failure:** [${{ env.WORKFLOW_NAME }}](https://github.com/${{ github.repository }}/actions/runs/${{ env.FAILED_WORKFLOW_ID }})

**Action Required:**
Manually review and fix the failing tests.

### Analysis
Check the auto-fix workflow logs for detailed error analysis.
`
            });

            console.log(`ğŸ“ Issue created: #${issue.data.number}`);

            try {
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issue.data.number,
                labels: ['bug', 'auto-fix-failed', 'needs-review']
              });
            } catch (e) {
              console.log(`âš ï¸ Label error: ${e.message}`);
            }
          } catch (error) {
            console.log(`âŒ Error: ${error.message}`);
          }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. CLEANUP & REPORTING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    - name: ğŸ“¦ Upload analysis artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: auto-fix-analysis-${{ github.run_id }}
        path: |
          gemini_attempt_*.md
          FIX_SUCCESS
        retention-days: 7
