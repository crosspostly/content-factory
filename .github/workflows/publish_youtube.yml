name: 2. Scheduled YouTube Publisher

on:
  schedule:
    - cron: '0 8 * * *' # Runs daily at 8 AM UTC
  workflow_dispatch:
    inputs:
      project_id:
        description: 'Project ID to publish'
        required: false
        type: string
      branch_name:
        description: 'Branch name containing the video'
        required: false
        type: string

jobs:
  publish:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: read
    
    steps:
    - name: Checkout repository (main branch)
      uses: actions/checkout@v4
      with:
        ref: 'main'
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        pip install requests google-generativeai pyyaml

    - name: Prepare environment variables
      id: env_setup
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Set variables from workflow_dispatch or defaults
        PROJECT_ID="${{ github.event.inputs.project_id }}"
        BRANCH_NAME="${{ github.event.inputs.branch_name }}"
        
        if [ -z "$PROJECT_ID" ]; then
          echo "PROJECT_ID not provided, will search schedule.json"
          PROJECT_ID="default"
        fi
        
        if [ -z "$BRANCH_NAME" ]; then
          BRANCH_NAME="project/${PROJECT_ID}"
        fi
        
        echo "project_id=${PROJECT_ID}" >> $GITHUB_OUTPUT
        echo "branch_name=${BRANCH_NAME}" >> $GITHUB_OUTPUT
        echo "\nEnvironment variables prepared:"
        echo "  PROJECT_ID: ${PROJECT_ID}"
        echo "  BRANCH_NAME: ${BRANCH_NAME}"

    - name: Find next video to publish from schedule
      id: scheduler
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python << 'EOF'
        import json
        import os
        from datetime import datetime
        from pathlib import Path
        
        # Check if schedule.json exists
        schedule_path = Path('schedule.json')
        if not schedule_path.exists():
            print("::warning::schedule.json not found. Creating default structure.")
            schedule_data = {
                "videos": [
                    {
                        "project_id": "default",
                        "branch": "project/default",
                        "title": "Default Video",
                        "description": "Default video for testing",
                        "thumbnail": "thumbnail.png",
                        "status": "pending",
                        "publishDate": "2025-12-28T08:00:00Z"
                    }
                ]
            }
        else:
            with open(schedule_path, 'r') as f:
                schedule_data = json.load(f)
        
        # Find first pending video with past publish date
        now = datetime.utcnow()
        video_to_publish = None
        
        for video in schedule_data.get('videos', []):
            if video.get('status') == 'pending':
                try:
                    pub_date = datetime.fromisoformat(
                        video.get('publishDate', '').replace('Z', '+00:00')
                    )
                    if pub_date <= now:
                        video_to_publish = video
                        break
                except:
                    # If publish date parsing fails, consider it ready
                    video_to_publish = video
                    break
        
        if video_to_publish:
            print(f"\nâœ… Found video to publish:")
            print(f"  Project ID: {video_to_publish.get('project_id')}")
            print(f"  Branch: {video_to_publish.get('branch')}")
            print(f"  Title: {video_to_publish.get('title')}")
            
            project_id = video_to_publish.get('project_id')
            branch = video_to_publish.get('branch')
            
            print(f"\n::set-output name=video_id::{project_id}")
            print(f"::set-output name=branch_name::{branch}")
            print(f"::set-output name=title::{video_to_publish.get('title')}")
            print(f"::set-output name=description::{video_to_publish.get('description')}")
            print(f"::set-output name=thumbnail::{video_to_publish.get('thumbnail')}")
        else:
            print("\nâš ï¸  No video found to publish in schedule")
            print("::set-output name=found::false")
        
        EOF

    - name: Validate credentials
      id: validate_creds
      env:
        YOUTUBE_CREDENTIALS: ${{ secrets.YOUTUBE_CREDENTIALS_JSON }}
      run: |
        if [ -z "$YOUTUBE_CREDENTIALS" ]; then
          echo "::warning::YouTube credentials (YOUTUBE_CREDENTIALS_JSON) not configured"
          echo "found=false" >> $GITHUB_OUTPUT
        else
          # Verify it's valid JSON
          echo "$YOUTUBE_CREDENTIALS" | python -m json.tool > /dev/null 2>&1
          if [ $? -eq 0 ]; then
            echo "âœ… YouTube credentials validated"
            echo "found=true" >> $GITHUB_OUTPUT
          else
            echo "::error::YouTube credentials is not valid JSON"
            echo "found=false" >> $GITHUB_OUTPUT
          fi
        fi

    - name: Find and download video artifact
      id: download
      if: steps.scheduler.outputs.video_id != ''
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        BRANCH_NAME: ${{ steps.scheduler.outputs.branch_name }}
      run: |
        python << 'EOF'
        import os
        import json
        import requests
        from pathlib import Path
        
        GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')
        REPO = os.getenv('GITHUB_REPOSITORY', 'crosspostly/content-factory')
        BRANCH = os.getenv('BRANCH_NAME', 'project/default')
        
        headers = {
            'Authorization': f'token {GITHUB_TOKEN}',
            'Accept': 'application/vnd.github.v3+json'
        }
        
        print(f"Searching for artifacts from branch: {BRANCH}")
        
        # Get workflow runs for the branch
        url = f"https://api.github.com/repos/{REPO}/actions/runs"
        params = {
            'branch': BRANCH,
            'status': 'completed',
            'per_page': 10
        }
        
        resp = requests.get(url, headers=headers, params=params)
        if resp.status_code != 200:
            print(f"::error::Failed to fetch runs: {resp.status_code}")
            print(f"Response: {resp.text}")
            exit(1)
        
        runs = resp.json().get('workflow_runs', [])
        print(f"Found {len(runs)} workflow runs")
        
        # Find first run with video artifacts
        artifact_found = False
        for run in runs:
            run_id = run['id']
            print(f"\nChecking run {run_id}...")
            
            # Get artifacts for this run
            artifacts_url = f"https://api.github.com/repos/{REPO}/actions/runs/{run_id}/artifacts"
            artifacts_resp = requests.get(artifacts_url, headers=headers)
            
            if artifacts_resp.status_code != 200:
                continue
            
            artifacts = artifacts_resp.json().get('artifacts', [])
            print(f"  Found {len(artifacts)} artifacts")
            
            for artifact in artifacts:
                if 'final-video' in artifact['name'] or '.mp4' in artifact['name']:
                    print(f"  âœ… Found video artifact: {artifact['name']}")
                    artifact_id = artifact['id']
                    
                    # Download artifact
                    download_url = artifact['archive_download_url']
                    download_resp = requests.get(download_url, headers=headers)
                    
                    Path('video_artifact').mkdir(exist_ok=True)
                    
                    # Extract and find MP4
                    import zipfile
                    import io
                    
                    zip_buffer = io.BytesIO(download_resp.content)
                    with zipfile.ZipFile(zip_buffer, 'r') as zip_ref:
                        zip_ref.extractall('video_artifact')
                    
                    mp4_files = list(Path('video_artifact').glob('**/*.mp4'))
                    if mp4_files:
                        video_path = mp4_files[0]
                        print(f"\nâœ… Artifact extracted: {video_path}")
                        print(f"::set-output name=video_path::{video_path}")
                        artifact_found = True
                        break
            
            if artifact_found:
                break
        
        if not artifact_found:
            print("::warning::No video artifact found")
            print(f"::set-output name=video_path::")
        
        EOF

    - name: Prepare YouTube metadata
      id: metadata
      if: steps.download.outputs.video_path != ''
      run: |
        TITLE="${{ steps.scheduler.outputs.title }}"
        DESCRIPTION="${{ steps.scheduler.outputs.description }}"
        THUMBNAIL="${{ steps.scheduler.outputs.thumbnail }}"
        
        echo "title=${TITLE}" >> $GITHUB_OUTPUT
        echo "description=${DESCRIPTION}" >> $GITHUB_OUTPUT
        echo "thumbnail=${THUMBNAIL}" >> $GITHUB_OUTPUT
        
        echo "\nðŸ“‹ Metadata prepared:"
        echo "  Title: ${TITLE}"
        echo "  Description: ${DESCRIPTION:0:100}..."
        echo "  Thumbnail: ${THUMBNAIL}"

    - name: Upload to YouTube (IMPLEMENTATION REQUIRED)
      if: steps.validate_creds.outputs.found == 'true' && steps.download.outputs.video_path != ''
      env:
        YOUTUBE_CREDENTIALS_JSON: ${{ secrets.YOUTUBE_CREDENTIALS_JSON }}
        VIDEO_FILE: ${{ steps.download.outputs.video_path }}
        VIDEO_TITLE: ${{ steps.metadata.outputs.title }}
        VIDEO_DESCRIPTION: ${{ steps.metadata.outputs.description }}
        THUMBNAIL_FILE: ${{ steps.metadata.outputs.thumbnail }}
      run: |
        python << 'EOF'
        import os
        import json
        import sys
        from pathlib import Path
        
        # TODO: Implement actual YouTube API upload
        # This requires:
        # 1. google-auth for OAuth2
        # 2. google-auth-oauthlib
        # 3. google-auth-httplib2
        # 4. google-api-python-client
        
        credentials_json = os.getenv('YOUTUBE_CREDENTIALS_JSON')
        video_file = os.getenv('VIDEO_FILE')
        video_title = os.getenv('VIDEO_TITLE')
        video_description = os.getenv('VIDEO_DESCRIPTION')
        thumbnail_file = os.getenv('THUMBNAIL_FILE')
        
        print(f"\nðŸ“¹ YouTube Upload Parameters:")
        print(f"  Video: {video_file}")
        print(f"  Title: {video_title}")
        print(f"  Description: {video_description:0:100}...")
        print(f"  Thumbnail: {thumbnail_file}")
        
        if not Path(video_file).exists():
            print(f"::error::Video file not found: {video_file}")
            sys.exit(1)
        
        # Placeholder for actual upload
        print(f"\nâš ï¸  YouTube API implementation required")
        print(f"This step needs google-api-python-client library and proper OAuth2 setup")
        
        # For now, just verify the video exists and is readable
        video_size = Path(video_file).stat().st_size
        print(f"\nâœ… Video file verified:")
        print(f"  Size: {video_size / (1024*1024):.2f} MB")
        
        EOF

    - name: Update schedule status
      if: steps.scheduler.outputs.video_id != ''
      env:
        VIDEO_ID: ${{ steps.scheduler.outputs.video_id }}
      run: |
        python << 'EOF'
        import json
        from pathlib import Path
        from datetime import datetime
        
        schedule_path = Path('schedule.json')
        if schedule_path.exists():
            with open(schedule_path, 'r') as f:
                schedule_data = json.load(f)
            
            # Update status for published video
            video_id = '${{ env.VIDEO_ID }}'
            for video in schedule_data.get('videos', []):
                if video.get('project_id') == video_id:
                    video['status'] = 'published'
                    video['publishedDate'] = datetime.utcnow().isoformat() + 'Z'
                    print(f"âœ… Updated status for {video_id} to 'published'")
                    break
            
            # Save updated schedule
            with open(schedule_path, 'w') as f:
                json.dump(schedule_data, f, indent=2)
        else:
            print("âš ï¸  schedule.json not found, skipping status update")
        
        EOF

    - name: Commit schedule changes
      if: steps.scheduler.outputs.video_id != ''
      run: |
        git config user.name "GitHub Actions"
        git config user.email "actions@github.com"
        
        if [ -f schedule.json ]; then
          git add schedule.json
          git commit -m "chore: update video publish status for ${{ steps.scheduler.outputs.video_id }}"
          git push origin main
          echo "âœ… Schedule updated and committed"
        else
          echo "âš ï¸  schedule.json not found, skipping commit"
        fi

    - name: Workflow summary
      if: always()
      run: |
        echo "\nðŸ“Š Workflow Execution Summary:"
        echo "  Scheduler status: ${{ steps.scheduler.outcome }}"
        echo "  Credentials valid: ${{ steps.validate_creds.outputs.found }}"
        echo "  Video found: ${{ steps.download.outputs.video_path != '' }}"
        echo "  Upload status: ${{ steps.upload.outcome }}"
        
        if [ "${{ steps.scheduler.outputs.video_id }}" != "" ]; then
          echo "\nâœ… Job completed for project: ${{ steps.scheduler.outputs.video_id }}"
        else
          echo "\nâš ï¸  No video was ready for publishing"
        fi
